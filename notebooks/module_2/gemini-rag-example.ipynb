{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a419351-e14b-45ad-bcd1-d2d34422a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env variables from current directory ->  False\n",
      "Loaded env variables from parent directory ->  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    loaded_env = load_dotenv(dotenv_path=\".env\", override=True)\n",
    "    print(\"Loaded env variables from current directory -> \", loaded_env)\n",
    "    if loaded_env == False:\n",
    "        loaded_env = load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "        print(\"Loaded env variables from parent directory -> \", loaded_env)\n",
    "load_env()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "# If there is no environment variable set for the API key, you can pass the API\n",
    "    # key to the parameter `google_api_key` of the `GoogleGenerativeAIEmbeddings`\n",
    "    # function: `google_api_key = \"key\"`.\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "053ba92b-c226-448e-87e6-0afc5fc7defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIR = \"./chroma_vectordb\"\n",
    "import nest_asyncio\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "def retrieve_docs(weburl: str, is_sitemap_url=False): \n",
    "    \n",
    "\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    loader = None \n",
    "    if is_sitemap_url: \n",
    "        loader = SitemapLoader(web_path=weburl)\n",
    "    else:\n",
    "        loader = WebBaseLoader(web_path=weburl)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    langchain_docs = []\n",
    "    for doc in docs:\n",
    "        text_content = doc.page_content\n",
    "        #print( type(text_content) )\n",
    "        # The text content between the substrings \"code, audio, image and video.\" to\n",
    "        # \"Cloud TPU v5p\" is relevant for this tutorial. You can use Python's `split()`\n",
    "        # to select the required content.\n",
    "        #text_content_1 = text_content.split(\"code, audio, image and video.\",1)[1]\n",
    "        #final_text = text_content_1.split(\"Cloud TPU v5p\",1)[0]\n",
    "        final_text = text_content\n",
    "        # Convert the text to LangChain's `Document` format\n",
    "        langchain_docs.append(Document(page_content=final_text, metadata={\"source\": \"local\"}))\n",
    "    print(\"No of documents retrieved : \", len(langchain_docs) )\n",
    "    # Save to disk\n",
    "    vectorstore = Chroma.from_documents(\n",
    "                     documents=langchain_docs,                 # Data\n",
    "                     embedding=gemini_embeddings,    # Embedding model\n",
    "                     persist_directory=PERSIST_DIR # Directory to save data\n",
    "                     )\n",
    "    vectorstore.persist()\n",
    "    print(\"No of Documents stored  : \" , len(langchain_docs))\n",
    "    return langchain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20a12e99-b8f6-4d8b-8332-2150b4ad7240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of documents retrieved :  1\n",
      "No of Documents stored  :  1\n"
     ]
    }
   ],
   "source": [
    "web_url = \"https://blog.google/technology/ai/google-gemini-ai/\"\n",
    "ret_docs = retrieve_docs(web_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a84b95-f775-45e3-a335-a4ffb425725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#####################################################################################################################################################################################| 219/219 [00:08<00:00, 25.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of documents retrieved :  219\n"
     ]
    },
    {
     "ename": "GoogleGenerativeAIError",
     "evalue": "Error embedding content: 504 Deadline Exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeadlineExceeded\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/langchain_google_genai/embeddings.py:227\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[0;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_embed_contents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBatchEmbedContentsRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:1379\u001b[0m, in \u001b[0;36mGenerativeServiceClient.batch_embed_contents\u001b[0;34m(self, request, model, requests, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDeadlineExceeded\u001b[0m: 504 Deadline Exceeded",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGoogleGenerativeAIError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m web_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.smith.langchain.com/sitemap.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m ret_docs \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweb_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_sitemap_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 35\u001b[0m, in \u001b[0;36mretrieve_docs\u001b[0;34m(weburl, is_sitemap_url)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo of documents retrieved : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(langchain_docs) )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save to disk\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlangchain_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Data\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m                 \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgemini_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Embedding model\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPERSIST_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Directory to save data\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39mpersist()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo of Documents stored  : \u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;28mlen\u001b[39m(langchain_docs))\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    886\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    838\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    839\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    840\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    841\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    842\u001b[0m     ):\n\u001b[0;32m--> 843\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/01-github-vjkhambe/.github-vjkhambe-env/lib/python3.11/site-packages/langchain_google_genai/embeddings.py:231\u001b[0m, in \u001b[0;36mGoogleGenerativeAIEmbeddings.embed_documents\u001b[0;34m(self, texts, batch_size, task_type, titles, output_dimensionality)\u001b[0m\n\u001b[1;32m    227\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbatch_embed_contents(\n\u001b[1;32m    228\u001b[0m             BatchEmbedContentsRequest(requests\u001b[38;5;241m=\u001b[39mrequests, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GoogleGenerativeAIError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError embedding content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;28mlist\u001b[39m(e\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39membeddings])\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[0;31mGoogleGenerativeAIError\u001b[0m: Error embedding content: 504 Deadline Exceeded"
     ]
    }
   ],
   "source": [
    "web_url = \"https://docs.smith.langchain.com/sitemap.xml\"\n",
    "ret_docs = retrieve_docs(web_url, is_sitemap_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b71aa23-3016-41ce-820f-309a1a59032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(): \n",
    "    # Load from disk\n",
    "    vectorstore_disk = Chroma(\n",
    "                            persist_directory=PERSIST_DIR,       # Directory of db\n",
    "                            embedding_function=gemini_embeddings   # Embedding model\n",
    "                       )\n",
    "    # Get the Retriever interface for the store to use later.\n",
    "    # When an unstructured query is given to a retriever it will return documents.\n",
    "    # Read more about retrievers in the following link.\n",
    "    # https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "    #\n",
    "    # Since only 1 document is stored in the Chroma vector store, search_kwargs `k`\n",
    "    # is set to 1 to decrease the `k` value of chroma's similarity search from 4 to\n",
    "    # 1. If you don't pass this value, you will get a warning.\n",
    "    retriever = vectorstore_disk.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "    # Check if the retriever is working by trying to fetch the relevant docs related\n",
    "    # to the word 'MMLU' (Massive Multitask Language Understanding). If the length is greater than zero, \n",
    "    # it means that the retriever is functioning well.\n",
    "    print(len(retriever.get_relevant_documents(\"MMLU\")))\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9881c-dcec-48b9-bac4-176bb856dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e134fa-76d9-4cee-96f3-b6ffce99d975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c31412-7d2c-492f-b63d-321b00fe319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(): \n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    # If there is no environment variable set for the API key, you can pass the API\n",
    "    # key to the parameter `google_api_key` of the `ChatGoogleGenerativeAI` function:\n",
    "    # `google_api_key=\"key\"`.\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                     temperature=0.7, top_p=0.85)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6720a8-fe7a-4868-a5eb-44f020a90234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt():\n",
    "    # Prompt template to query Gemini\n",
    "    llm_prompt_template = \"\"\"You are an assistant for question-answering tasks.\n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer, just say that you don't know.\n",
    "    Use five sentences maximum and keep the answer concise.\\n\n",
    "    Question: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "    \n",
    "    llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "    \n",
    "    print(llm_prompt)\n",
    "    return llm_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b141f-b516-42b4-bee4-70cf6a0912ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = get_retriever()\n",
    "llm = get_llm()\n",
    "llm_prompt = get_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7bb6b-888a-49a5-9020-424bb379ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine data from documents to readable string format.\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create stuff documents chain using LCEL.\n",
    "# This is called a chain because you are chaining together different elements\n",
    "# with the LLM. In the following example, to create the stuff chain, you will\n",
    "# combine the relevant context from the website data matching the question, the\n",
    "# LLM model, and the output parser together like a chain using LCEL.\n",
    "#\n",
    "# The chain implements the following pipeline:\n",
    "# 1. Extract the website data relevant to the question from the Chroma\n",
    "#    vector store and save it to the variable `context`.\n",
    "# 2. `RunnablePassthrough` option to provide `question` when invoking\n",
    "#    the chain.\n",
    "# 3. The `context` and `question` are then passed to the prompt where they\n",
    "#    are populated in the respective variables.\n",
    "# 4. This prompt is then passed to the LLM (`gemini-pro`).\n",
    "# 5. Output from the LLM is passed through an output parser\n",
    "#    to structure the model's response.\n",
    "def get_dynamic_chain(retriever, format_docs, llm_prompt, llm): \n",
    "    return (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | llm_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "chain = get_dynamic_chain(retriever, format_docs, llm_prompt, llm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6f582aa-6a66-478f-9647-258428c9ac32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but this article does not contain the answer to your question about what Gemini is.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is Gemini?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c493b0-fc1e-4e2a-90c0-94144df448d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot find the answer to your question in the provided context.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6557f68-d575-4c95-aa7f-bdfc40efee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is langsmith?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d7bfa-7e27-42f0-bfe2-38405b29d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is llama?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f3118-e2d1-466e-b291-3b671feafc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"which env variables needed for langsmith?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fff20-7332-41e9-abb5-10e7aaadeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"how to add evaluaters for LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f07831-8004-49ed-821c-92b90cb135fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"what is chain in langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709ba40-187d-4e01-990c-b5840da13e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"is langsmith free to use for enterprise?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f03dbbd-061e-4fa1-93bf-6f37db35182d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
